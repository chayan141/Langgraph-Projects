{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPu19WCFMrCTzM5G25PqkWX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chayan141/Langgraph-Projects/blob/main/Langgraph_Long_Memory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Long Term Memory General"
      ],
      "metadata": {
        "id": "NYfyK-IHTZVG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Semantic Memory : Facts about the users.\n",
        "\n",
        "Episodic Memory : Involves recalling Past Experience or events or acions. It is sometimes implemented through the fewshot prompting.\n",
        "\n",
        "Procedural Memory : Both humans and AI agents remembers set of rules to perform any tasks."
      ],
      "metadata": {
        "id": "7lOtvEmuUEc0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qDwTWzimQ42U"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install -U langchain_openai langgraph trustcall langchain_core langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "gemini = userdata.get('gemini_api_key')\n",
        "import os\n",
        "os.environ['gemini_api_key'] = gemini"
      ],
      "metadata": {
        "id": "bXOc7cfeYJf_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI"
      ],
      "metadata": {
        "id": "9gXvaxieYf4V"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ChatGoogleGenerativeAI(model='gemini-2.0-flash',api_key=gemini)"
      ],
      "metadata": {
        "id": "JBjEP33TYhb8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnableConfig\n",
        "from langgraph.config import get_store\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langgraph.store.memory import InMemoryStore"
      ],
      "metadata": {
        "id": "OcZm4Z2IYj9g"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store = InMemoryStore()"
      ],
      "metadata": {
        "id": "0cay5aaUYnJW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TypedDict instance\n",
        "user_profile = {\n",
        "    \"user_name\": \"Lance\",\n",
        "    \"interests\": [\"biking\", \"technology\", \"coffee\"]\n",
        "}\n",
        "user_profile"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pe9AUDbmYqkD",
        "outputId": "e7e10c7a-20cc-40ae-b96c-3429e67c287a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'user_name': 'Lance', 'interests': ['biking', 'technology', 'coffee']}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "namespace_for_memory = (\"1\", \"memory\")\n",
        "\n",
        "key = \"user_profile\"\n",
        "value = user_profile"
      ],
      "metadata": {
        "id": "IRjoZjs9YxxB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store.put(namespace_for_memory, key, value)"
      ],
      "metadata": {
        "id": "FJd8g8bMZpKm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for m in store.search(namespace_for_memory):\n",
        "    print(m.dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uC5Yp_UgZsMN",
        "outputId": "15127264-6150-4c84-c065-1dd42cb89553"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'namespace': ['1', 'memory'], 'key': 'user_profile', 'value': {'user_name': 'Lance', 'interests': ['biking', 'technology', 'coffee']}, 'created_at': '2025-07-04T03:06:57.182191+00:00', 'updated_at': '2025-07-04T03:06:57.182196+00:00', 'score': None}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(m)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "mtpjoG6uZ1aA",
        "outputId": "6491460b-f15c-4787-b109-a07598c74387"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "langgraph.store.base.SearchItem"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>langgraph.store.base.SearchItem</b><br/>def __init__(namespace: tuple[str, ...], key: str, value: dict[str, Any], created_at: datetime, updated_at: datetime, score: float | None=None) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/langgraph/store/base/__init__.py</a>Represents an item returned from a search operation with additional metadata.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 119);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "profile = store.get(namespace_for_memory, key)\n",
        "profile.value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVcKLrinaAi4",
        "outputId": "466498bf-ef02-4371-f9fd-e2b8cfdfd869"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'user_name': 'Lance', 'interests': ['biking', 'technology', 'coffee']}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read Long Term Memory"
      ],
      "metadata": {
        "id": "q9zreMR2bwP6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_user_info(config: RunnableConfig):\n",
        "  \"\"\"Look up user info.\"\"\"\n",
        "    # Same as that provided to `create_react_agent`\n",
        "  store = get_store()\n",
        "  user_id = config['configurable'].get(\"user_id\")\n",
        "  user_info = store.get((\"1\",  \"memory\"), user_id)\n",
        "  return user_info.value if user_info else \"Unknown Users\""
      ],
      "metadata": {
        "id": "CxWJ9t4raKS4"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = create_react_agent(\n",
        "    model = model,\n",
        "    tools = [get_user_info],\n",
        "    store = store\n",
        ")"
      ],
      "metadata": {
        "id": "mufhhDzXa4sQ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.invoke(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"look up user information\"}]},\n",
        "    config={\"configurable\": {\"user_id\": \"1\"}}\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roChRVp6bKNH",
        "outputId": "9feec4df-5f71-43ac-b6a4-a790214a56c6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='look up user information', additional_kwargs={}, response_metadata={}, id='67009cc5-69a8-4aa4-88b7-414982837d87'),\n",
              "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'get_user_info', 'arguments': '{}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--0a3574db-a75c-42b9-a751-fa02f90d12d9-0', tool_calls=[{'name': 'get_user_info', 'args': {}, 'id': 'ce3fab0f-eb7d-49dd-936d-7a910fc48025', 'type': 'tool_call'}], usage_metadata={'input_tokens': 14, 'output_tokens': 5, 'total_tokens': 19, 'input_token_details': {'cache_read': 0}}),\n",
              "  ToolMessage(content='Unknown Users', name='get_user_info', id='369df786-8572-45ac-b478-bc8895bc8f63', tool_call_id='ce3fab0f-eb7d-49dd-936d-7a910fc48025'),\n",
              "  AIMessage(content='I looked up the user information and the result is \"Unknown Users\".', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--e996de24-9b12-49f1-a6f8-35d4e15c7097-0', usage_metadata={'input_tokens': 27, 'output_tokens': 15, 'total_tokens': 42, 'input_token_details': {'cache_read': 0}})]}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Write Long Term Memory"
      ],
      "metadata": {
        "id": "YK-pJsQGbziH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import TypedDict\n",
        "from typing import List\n",
        "\n",
        "from langgraph.config import get_store\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langgraph.store.memory import InMemoryStore\n",
        "\n",
        "store = InMemoryStore()\n",
        "\n",
        "class UserProfile(TypedDict):\n",
        "    \"\"\"User profile schema with typed fields\"\"\"\n",
        "    user_name: str  # The user's preferred name\n",
        "    interests: List[str]  # A list of the user's interests"
      ],
      "metadata": {
        "id": "ijQZ2-0vbjiX"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_user_info(user_info: UserProfile, config: RunnableConfig):\n",
        "    \"\"\"Save user info.\"\"\"\n",
        "\n",
        "    store = get_store()\n",
        "    user_id = config['configurable'].get(\"user_id\")\n",
        "    store.put((\"2\", \"memory\"), user_id, user_info)\n",
        "    return \"Success\""
      ],
      "metadata": {
        "id": "pBrtI9yHc7H8"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = create_react_agent(\n",
        "    model = model,\n",
        "    tools = [save_user_info],\n",
        "    store = store\n",
        ")"
      ],
      "metadata": {
        "id": "MM1X0dpQdMfV"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the agent\n",
        "agent.invoke(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"My name is John Smith, I have interests in bike riding\"}]},\n",
        "    config={\"configurable\": {\"user_id\": \"user_123\"}}\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfZPse1TdMdI",
        "outputId": "5a957824-a842-4024-9db7-cf736dd65dc0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='My name is John Smith, I have interests in bike riding', additional_kwargs={}, response_metadata={}, id='09409924-a871-4fd2-8cc5-45fe42e99fd4'),\n",
              "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'save_user_info', 'arguments': '{\"user_info\": {\"interests\": [\"bike riding\"], \"user_name\": \"John Smith\"}}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--567b2f99-9f5e-4823-aaae-08eb57ab4989-0', tool_calls=[{'name': 'save_user_info', 'args': {'user_info': {'interests': ['bike riding'], 'user_name': 'John Smith'}}, 'id': '94c0065c-a7d1-4644-accb-7f70ff35bc64', 'type': 'tool_call'}], usage_metadata={'input_tokens': 46, 'output_tokens': 16, 'total_tokens': 62, 'input_token_details': {'cache_read': 0}}),\n",
              "  ToolMessage(content='Success', name='save_user_info', id='fc9fa25a-523a-41bf-b6f0-3bfe5ef54052', tool_call_id='94c0065c-a7d1-4644-accb-7f70ff35bc64'),\n",
              "  AIMessage(content=\"OK. I've saved your user information.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--a43b3f11-d27b-4f8b-8826-736379964ebc-0', usage_metadata={'input_tokens': 69, 'output_tokens': 11, 'total_tokens': 80, 'input_token_details': {'cache_read': 0}})]}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "namespace_for_memory = (\"2\", \"memory\")\n",
        "for m in store.search(namespace_for_memory):\n",
        "    print(m.dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aw0YPUupdMap",
        "outputId": "8e5b108f-1f3b-4c1d-f4fb-41b4b9f81141"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'namespace': ['2', 'memory'], 'key': 'user_123', 'value': {'user_name': 'John Smith', 'interests': ['bike riding']}, 'created_at': '2025-07-04T03:27:16.376406+00:00', 'updated_at': '2025-07-04T03:27:16.376410+00:00', 'score': None}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Complex Schema Processing Using TrustCall"
      ],
      "metadata": {
        "id": "PwhQhN9xewJv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Complex schemas can be difficult to extract.\n",
        "\n",
        "In addition, updating even simple schemas can pose challenges.\n",
        "\n",
        "Consider our above chatbot.\n",
        "\n",
        "We regenerated the profile schema from scratch each time we chose to save a new memory.\n",
        "\n",
        "This is inefficient, potentially wasting model tokens if the schema contains a lot of information to re-generate each time.\n",
        "\n",
        "Worse, we may loose information when regenerating the profile from scratch.\n",
        "\n",
        "Addressing these problems is the motivation for TrustCall!"
      ],
      "metadata": {
        "id": "KdlddfM4fXm7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
        "# Conversation\n",
        "conversation = [HumanMessage(content=\"Hi, I'm Lance.\"),\n",
        "                AIMessage(content=\"Nice to meet you, Lance.\"),\n",
        "                HumanMessage(content=\"I really like biking around San Francisco.\")]"
      ],
      "metadata": {
        "id": "pA8lVl13dMWV"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from trustcall import create_extractor\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "\n",
        "\n",
        "# Schema\n",
        "class UserProfile(BaseModel):\n",
        "    \"\"\"User profile schema with typed fields\"\"\"\n",
        "    user_name: str = Field(description=\"The user's preferred name\")\n",
        "    interests: List[str] = Field(description=\"A list of the user's interests\")"
      ],
      "metadata": {
        "id": "IGC-XmoydMTw"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the extractor\n",
        "trustcall_extractor = create_extractor(\n",
        "    model,\n",
        "    tools=[UserProfile],\n",
        "    tool_choice=\"UserProfile\"\n",
        ")"
      ],
      "metadata": {
        "id": "b4vCy1a1dMRS"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instruction\n",
        "system_msg = \"Extract the user profile from the following conversation\"\n",
        "\n",
        "# Invoke the extractor\n",
        "result = trustcall_extractor.invoke({\"messages\": [SystemMessage(content=system_msg)]+conversation})"
      ],
      "metadata": {
        "id": "GdQu-oRtdMOv"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for m in result[\"messages\"]:\n",
        "    m.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R12300p9dMMJ",
        "outputId": "4a32f39c-b132-4ae4-c0f2-10ed7678d496"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  UserProfile (1d6851df-f4dd-4eda-bcd6-01c1e81e8f17)\n",
            " Call ID: 1d6851df-f4dd-4eda-bcd6-01c1e81e8f17\n",
            "  Args:\n",
            "    interests: ['biking']\n",
            "    user_name: Lance\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "schema = result[\"responses\"]\n",
        "schema"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TWq3FsOdMJZ",
        "outputId": "17a76e12-9b43-4a1c-f255-c4cd925a9e04"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[UserProfile(user_name='Lance', interests=['biking'])]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "schema[0].model_dump()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XzqL2SFgPTx",
        "outputId": "44d441f5-6c03-4bda-aa3d-9052ec4b2fd1"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'user_name': 'Lance', 'interests': ['biking']}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result[\"response_metadata\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pC6kQxHFgTQu",
        "outputId": "c73f0436-17b7-42e6-c362-f30a966968d0"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'id': '1d6851df-f4dd-4eda-bcd6-01c1e81e8f17'}]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update the conversation\n",
        "updated_conversation = [HumanMessage(content=\"Hi, I'm Lance.\"),\n",
        "                        AIMessage(content=\"Nice to meet you, Lance.\"),\n",
        "                        HumanMessage(content=\"I really like biking around San Francisco.\"),\n",
        "                        AIMessage(content=\"San Francisco is a great city! Where do you go after biking?\"),\n",
        "                        HumanMessage(content=\"I really like to go to a bakery after biking.\"),]"
      ],
      "metadata": {
        "id": "FNEAWjxPgaoQ"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update the instruction\n",
        "system_msg = f\"\"\"Update the memory (JSON doc) to incorporate new information from the following conversation\"\"\""
      ],
      "metadata": {
        "id": "gc-b2S4Dgepj"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Invoke the extractor with the updated instruction and existing profile with the corresponding tool name (UserProfile)\n",
        "result = trustcall_extractor.invoke({\"messages\": [SystemMessage(content=system_msg)]+updated_conversation},\n",
        "                                    {\"existing\": {\"UserProfile\": schema[0].model_dump()}})\n",
        "\n",
        "for m in result[\"messages\"]:\n",
        "    m.pretty_print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "781zLNe8ghc5",
        "outputId": "38914a92-b344-477b-b1fb-d5ebca5649ed"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  UserProfile (3e39644d-6a29-4567-89a3-959f96d208b7)\n",
            " Call ID: 3e39644d-6a29-4567-89a3-959f96d208b7\n",
            "  Args:\n",
            "    interests: ['biking', 'bakery']\n",
            "    user_name: Lance\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result[\"response_metadata\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIg5NtSJgqfv",
        "outputId": "07e45ffa-e0ec-48aa-8659-7bf967765cbc"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'id': '3e39644d-6a29-4567-89a3-959f96d208b7'}]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "updated_schema = result[\"responses\"][0]\n",
        "updated_schema.model_dump()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfdugaxeguMY",
        "outputId": "62ed925e-e0a7-4b0d-b980-9ca6ed576930"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'user_name': 'Lance', 'interests': ['biking', 'bakery']}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FXhVnAiBgvhI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}